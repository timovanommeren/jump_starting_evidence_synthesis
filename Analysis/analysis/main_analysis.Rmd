---
title: "TDD_100"
output: html_document
date: "2025-10-28"
---
```{r}
library(here)

source(here("Analysis/R/00_packages.R"))
source(here("Analysis/R/01_load_data.R"))
source(here("Analysis/R/02_prepare_data.R"))
source(here("Analysis/R/03_descriptives.R"))
# source(here("R/04_models.R"))
# source(here("R/05_plots.R"))

load_packages()

```

## Loading and transforming data

```{r load and transform data}

# import simulation results and metadata
raw <- load_simulation_data()

# (1) transform simulation data to wide
# (2) adjust metadata column names, and, 
# (3) add the number of records and percent_rel of relevant records from metadata to simulation data (these will serve as group-level predictors in multilevel model)
processed <- prepare_data(raw$simulation, raw$meta)

# assign to variables for easier access
simulation_long <- raw$simulation
simulation      <- processed$simulation
metadata        <- processed$meta

```


## Descriptives

### Summary statistics

```{r}
head(simulation)
summary(simulation)

#export summary data to latex format text file 
```


### Descriptive plots

#### Bar chart of number of relevant records found per dataset and condition

```{r}

descriptive_barchart(simulation, metadata)

```


## Data Analysis

### Checking assumptions


```{r}
#check the assumption of homogeneity of variance across conditions
ggplot(simulation, aes(x = condition, y = td)) +
  geom_boxplot() +
  geom_jitter(width = 0.1, alpha = .3)
```


```{r, run=FALSE}}
# check the assumption of linearity between percentage and relevant records found
ggplot(simulation,
       aes(x = percent_rel, y = td)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm",
              aes(color = "linear"),
              se = FALSE) +
  geom_smooth(method = "lm",
              formula = y ~ x + I(x^2),
              aes(color = "quadratic"),
              se = FALSE) +
  labs(
    title = "Percentage of relevant records vs. number of relevant records found",
    x = "percentage of relevant records",
    y = "Number of relevant records found in first 100 screened"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    panel.background = element_rect(fill = "white", color = NA),
    plot.background  = element_rect(fill = "white", color = NA),
    legend.background = element_rect(fill = "white", color = NA),
    legend.key = element_rect(fill = "white", color = NA),
    plot.margin = margin(10, 20, 10, 10)
  )

# check the assumption of linearity between percentage and relevant records found
ggplot(simulation,
       aes(x = records, y = td)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm",
              aes(color = "linear"),
              se = FALSE) +
  geom_smooth(method = "lm",
              formula = y ~ x + I(x^2),
              aes(color = "quadratic"),
              se = FALSE) +
  labs(
    title = "Total number of records vs. number of relevant records found",
    x = "Percentage of relevant records",
    y = "Number of relevant records found in first 100 screened"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    panel.background = element_rect(fill = "white", color = NA),
    plot.background  = element_rect(fill = "white", color = NA),
    legend.background = element_rect(fill = "white", color = NA),
    legend.key = element_rect(fill = "white", color = NA),
    plot.margin = margin(10, 20, 10, 10)
  )

```



### Mixed effects model

A bottom-up modeling approach is used to build the mixed effects model. We start with an intercept-only model and subsequently add fixed effects and random slopes. At each step, we evaluate whether the addition of parameters significantly improves model fit using likelihood ratio tests.

####

```{r}
#set reference category for regression model
simulation <- simulation %>% mutate(condition = relevel(factor(condition), ref = "llm"))
```



#### Intercept only model

```{r}
model0 <- lmer(td ~ 1 + (1|dataset), REML = F, data = simulation)
summary(model0)
```

```{r}
Intercept_variances = as.data.frame(VarCorr(model0))

ICC = Intercept_variances[Intercept_variances$grp == 'dataset','vcov'] / (Intercept_variances[Intercept_variances$grp == 'dataset','vcov'] + Intercept_variances[Intercept_variances$grp == 'Residual','vcov'])

print(ICC)
```

```{r}

model1 <- lmer(td ~ condition  + (1|dataset), REML = F, data = simulation)
summary(model2)
anova(model2, model1)
```


```{r}
#grand mean centering of continuous predictors
simulation <- simulation %>%
  mutate(
    n_abstracts       = n_abstracts - mean(n_abstracts),
    length_abstracts  = length_abstracts - mean(length_abstracts),
    llm_temperature   = llm_temperature - mean(llm_temperature),
    records           = records - mean(records),
    percent_rel               = percent_rel - mean(percent_rel)
  )

#scale 'records' variable
simulation$records <- scale(simulation$records)

```


```{r}

model2 <- lmer(td ~ condition + n_abstracts + length_abstracts + llm_temperature + (1|dataset), REML = F, data = simulation)
summary(model2)
anova(model2, model1)
```


15742    

```{r}
model3 <- lmer(td ~ condition + n_abstracts + length_abstracts + llm_temperature + records + percent_rel + (1|dataset), REML = F, data = simulation)
summary(model3)
anova(model3, model2)
```

```{r}
model4 <- lmer(td ~ condition + n_abstracts + length_abstracts + llm_temperature + records + percent_rel + (condition|dataset), REML = F, data = simulation)
summary(model4)
anova(model4, model3)
```

The negative correlations between the random intercepts and random slopes indicate that in datasets where performance under the reference condition (LLM) is higher than average, the drop in performance when using minimal or no_priors instead of LLM is larger than average. In other words, the effect of initialization was more pronounced for datasets where the overall performance was higher in general. Some datasets are simply easier for the active learning model of ASReview: many relevant records can be found early. In those ‘easier’ datasets, LLM-based initialization tends to create an especially large advantage over minimal or no_priors, which is reflected in the strong negative correlations between the random intercept and the random slopes.

```{r}
model5 <- lmer(td ~ condition + n_abstracts + length_abstracts + llm_temperature + records + percent_rel + condition*percent_rel + (condition|dataset), REML = F, data = simulation)
summary(model5)
anova(model5, model4)
```


## Exporting Results


```{r}

p_apa <- function(p) ifelse(is.na(p), "NA", ifelse(p < .001, "$p$ < .001", sprintf("$p$ = %.3f", p)))


#undo scientific notation
options(scipen = 999)

# limit to 2 decimal places
  
# ---- Build LaTeX paragraph
latex_text <- paste0(
  "We fit a linear regression to examine whether initialization affected the number of ",
  "relevant records found within the first 100 screenings. ",
  "The LLM-initialized model yielded on average \\textit{B} = ", round(summary_basic$coefficients[1, 1],2),
  ", \\textit{SE} = ", round(summary_basic$coefficients[1, 2],2),
  ", \\textit{t} = ", round(summary_basic$coefficients[1, 3],2),
  ". ",

  "Interestingly, this is approximately equal to number of papers found in the random-initialization condition, at a difference of:, ",
  "\\textit{B} = ", round(summary_basic$coefficients[2, 1],2),
  ", \\textit{SE} = ", round(summary_basic$coefficients[2, 2],2),
  ", \\textit{t} = ", round(summary_basic$coefficients[2, 3],2),
  ", ", p_apa(summary_basic$coefficients[2, 4]),
  ". ",
  
  "In contrast, the difference between the LLM-initialization and the no-initialization conditions was statistically significant: ",
  "\\textit{B} = ", round(summary_basic$coefficients[3, 1],2),
  ", \\textit{SE} = ", round(summary_basic$coefficients[3, 2],2),
  ", \\textit{t} = ", round(summary_basic$coefficients[3, 3],2),
  ", ", p_apa(summary_basic$coefficients[3, 4]),
  ".\n",
  "Overall model fit was $R^2$ = ", round(summary_basic$r.squared,2),
  ", adjusted $R^2$ = ", round(summary_basic$adj.r.squared,2),
  ", and $F(", Df1, ", ", Df2, ")$ = ", round(summary_basic$fstatistic[1],2),
  ", \\textit{p} = ", p_apa(anova_basic$'Pr(>F)'[1]), "."
)

# ---- Print LaTeX to console (or write to a .tex file)
cat(latex_text)
writeLines(latex_text, "../Report/results/results_paragraph.tex")

```


```{r}
subset(as.data.frame(VarCorr(model2)), grp == "dataset")$vcov
subset(as.data.frame(VarCorr(model2)), grp == "Residual")$vcov
```

```{r}

random_effects <- function(model){
  
  round_to = 3
  
  if (nrow(as.data.frame(VarCorr(model))) == 2) {
    
    return(
      list(
        residual_var = round(subset(as.data.frame(VarCorr(model)), grp == "Residual")$vcov, round_to),
        intercept_var= round(subset(as.data.frame(VarCorr(model)), grp == "dataset")$vcov, round_to)
        
      )
    )
  }
  else {
    list(
      residual_var = round(subset(as.data.frame(VarCorr(model)), grp == "Residual")$vcov, round_to),
      intercept_var= round(subset(as.data.frame(VarCorr(model)), grp == "dataset")$vcov[1], round_to),
      random_init_var= round(subset(as.data.frame(VarCorr(model)), grp == "dataset")$vcov[2], round_to),
      no_init_var= round(subset(as.data.frame(VarCorr(model)), grp == "dataset")$vcov[3], round_to),
      cor_random_init_intercept= round(subset(as.data.frame(VarCorr(model)), grp == "dataset")$sdcor[4], round_to),
      cor_no_init_intercept= round(subset(as.data.frame(VarCorr(model)), grp == "dataset")$sdcor[5], round_to),
      cor_no_init_random_init= round(subset(as.data.frame(VarCorr(model)), grp == "dataset")$sdcor[6], round_to)
    )
  }
}

random_effects(model4)

```


```{r}

p_to_stars <- function(p) {
  if (is.na(p)) return("")
  if (p < 0.001) return("***")
  if (p < 0.01)  return("**")
  if (p < 0.05)  return("*")
  ""
}


stargazer(
  model1, model2, model3, model4, model5,
  # column.labels = c("Conds", "Within", "Between", "Rand effects", "Interactions"),
  # column.separate = c(1, 1, 1, 1, 1),
  type = "latex",
  title = "Effect of initialisation on the number relevant records found in first 100 screened",
  dep.var.labels = "Outcome: number of records found",
  covariate.labels = c(
     "\\multirow{2}{*}{\\shortstack[l]{Random\\\\initialisation}}",
     "\\multirow{2}{*}{\\shortstack[l]{No\\\\initialisation}}",
    "\\multirow{2}{*}{\\shortstack[l]{Number of \\\\ abstracts}}",
    "\\multirow{2}{*}{\\shortstack[l]{Length \\\\ abstracts}}",
    "\\multirow{2}{*}{\\shortstack[l]{LLM \\\\ temperature.}}",
    "\\multirow{2}{*}{\\shortstack[l]{Dataset size \\\\ (N records)}}",
    "\\multirow{2}{*}{\\shortstack[l]{\\% relevant records}}",
    "\\multirow{2}{*}{\\shortstack[l]{\\% x Random \\\\ initialisation}}",
    "\\multirow{2}{*}{\\shortstack[l]{\\% x No initialisation}}"
  ),
  add.lines = list(
    
    c("$\\mathrm{Var}(u_{0j})$",
      random_effects(model1)$intercept_var, 
      random_effects(model2)$intercept_var, 
      random_effects(model3)$intercept_var, 
      random_effects(model4)$intercept_var, 
      random_effects(model5)$intercept_var
      ),
    
    c("$\\mathrm{Var}(u_{1j})$",
      "", 
      "", 
      "", 
      random_effects(model4)$random_init_var, 
      random_effects(model5)$random_init_var
      ),
    
    c("$\\mathrm{Var}(u_{2j})$",
      "",
      "",
      "",
      random_effects(model4)$no_init_var,
      random_effects(model5)$no_init_var
      ),
    
        c("$\\mathrm{Var}(\\varepsilon_{ij})$",
      random_effects(model1)$residual_var, 
      random_effects(model2)$residual_var, 
      random_effects(model3)$residual_var, 
      random_effects(model4)$residual_var, 
      random_effects(model5)$residual_var
      ),
    
    c("$\\rho(u_{0j}, u_{1j})$",
      "",
      "",
      "",
      random_effects(model4)$cor_random_init_intercept,
      random_effects(model5)$cor_random_init_intercept
      ),
    c("$\\rho(u_{0j}, u_{2j})$",
      "",
      "",
      "",
      random_effects(model4)$cor_no_init_intercept,
      random_effects(model5)$cor_no_init_intercept
      ),
    c("$\\rho(u_{1j}, u_{2j})$",
      "",
      "",
      "",
      random_effects(model4)$cor_no_init_random_init,
      random_effects(model5)$cor_no_init_random_init
      ),
    c("$\\Delta$ deviance (df)",
      "",
      paste0(round(anova(model1, model2)$Chisq[2],2), " (", anova(model1, model2)$Df[2], ")", p_to_stars(anova(model1, model2)$'Pr(>Chisq)'[2])),
      paste0(round(anova(model2, model3)$Chisq[2],2), " (", anova(model2, model3)$Df[2], ")", p_to_stars(anova(model2, model3)$'Pr(>Chisq)'[2])),
      paste0(round(anova(model3, model4)$Chisq[2],2), " (", anova(model3, model4)$Df[2], ")", p_to_stars(anova(model3, model4)$'Pr(>Chisq)'[2])),
      paste0(round(anova(model4, model5)$Chisq[2],2), " (", anova(model4, model5)$Df[2], ")", p_to_stars(anova(model4, model5)$'Pr(>Chisq)'[2]))
      )
  ),
  #no.space = TRUE,
  keep.stat = c("aic", "ll"),
  star.cutoffs = NA,
  notes.align	= "l",
  # notes = "\\parbox{0.9\\textwidth}{Model 1 includes only initialization conditions, Model 2 adds within-dataset covariates, Model 3 adds between-dataset covariates, Model 4 adds random slopes for initialization, and Model 5 adds interaction terms. $^{*} p<0.1; ^{**} p<0.05; ^{***} p<0.01$}",
  notes.label  = "",
  notes = c(
    "Model 1: only initialization conditions.",
    "Model 2: adds within-dataset covariates.",
    "Model 3: adds between-dataset covariates.",
    "Model 4: adds random effects for initialization.",
    "Model 5: adds interaction terms.",
    "$^{*} p<0.1; ^{**} p<0.05; ^{***} p<0.01$"
  ),
  notes.append  = FALSE,
  header = TRUE,
  out = here::here("Report/results/results_table.tex")
)



```



